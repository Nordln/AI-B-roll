{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bl3m7xb4OyjY"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LELlAM5Qc6W_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ill8gm7v\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ill8gm7v\n",
      "  Resolved https://github.com/openai/whisper.git to commit 5979f03701209bb035a0a466f14131aeb1116cbb\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numba (from openai-whisper==20240930)\n",
      "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20240930) (1.24.2)\n",
      "Collecting torch (from openai-whisper==20240930)\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux2014_aarch64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20240930) (4.66.5)\n",
      "Collecting more-itertools (from openai-whisper==20240930)\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20240930) (0.8.0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper==20240930)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Collecting networkx (from torch->openai-whisper==20240930)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (2024.9.0)\n",
      "Collecting sympy==1.13.1 (from torch->openai-whisper==20240930)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->openai-whisper==20240930)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->openai-whisper==20240930) (3.0.1)\n",
      "Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Downloading numba-0.60.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp311-cp311-manylinux2014_aarch64.whl (91.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (42.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803560 sha256=a401009a965da7c9ae9c8c96a140c086cda1a8d9b3e579b845977add6ac1c369\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jiy0v0si/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: mpmath, sympy, networkx, more-itertools, llvmlite, torch, numba, openai-whisper\n",
      "Successfully installed llvmlite-0.43.0 more-itertools-10.5.0 mpmath-1.3.0 networkx-3.4.2 numba-0.60.0 openai-whisper-20240930 sympy-1.13.1 torch-2.5.1\n",
      "Collecting pytube\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "Installing collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (1.51.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
      "  Downloading imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2014_aarch64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.11/site-packages (from moviepy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.11/site-packages (from moviepy) (1.24.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.11/site-packages (from moviepy) (2.32.3)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.11/site-packages (from imageio<3.0,>=2.5->moviepy) (10.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.8.30)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading imageio-2.36.0-py3-none-any.whl (315 kB)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2014_aarch64.whl (22.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110711 sha256=561fd7a9fc76abb586d202511b699b71411b559463a731febefaaad2ad5f3d5c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/83/b1/d9/119ef7c144b44d591ec0a9a140465133c23ea95d2a161184ba\n",
      "Successfully built moviepy\n",
      "Installing collected packages: proglog, imageio_ffmpeg, imageio, decorator, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 imageio-2.36.0 imageio_ffmpeg-0.5.1 moviepy-1.0.3 proglog-0.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install pytube\n",
    "!pip install openai\n",
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeIlmsLJ1CRH"
   },
   "source": [
    "### Workflow\n",
    "\n",
    "1. Generate captions for input video\n",
    "2. Identify keywords which represent these captions and can be used to find relevant videos in Pexels library\n",
    "\n",
    "- Example :\n",
    "\n",
    " - AI is used to automate many of the human tasks -> Automation\n",
    "\n",
    "3. Fetch pexels videos for these keywords to use as b-roll videos\n",
    "4. Stitch together the b-roll videos with original video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZOoycFKPCFz"
   },
   "source": [
    "### Extract audio from video with ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFfpIZwle9cn"
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i video.mp4 -ab 160k -ac 2 -ar 44100 -vn audio.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNmwdwaPPG_j"
   },
   "source": [
    "### Generate subtiles for the audio using whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db21samCfLDg",
    "outputId": "18cc7265-90ad-447b-e216-a4ab48941c12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [01:14<00:00, 20.6MiB/s]\n",
      "/opt/conda/lib/python3.11/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/opt/conda/lib/python3.11/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/whisper/transcribe.py:139\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, carry_initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    136\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[1;32m    141\u001b[0m content_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(content_frames \u001b[38;5;241m*\u001b[39m HOP_LENGTH \u001b[38;5;241m/\u001b[39m SAMPLE_RATE)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/whisper/audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[0;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/whisper/audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/subprocess.py:1950\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1949\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1951\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# Load the model\n",
    "model = whisper.load_model(\"medium\")\n",
    "result = model.transcribe(\"audio.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pogq_ThKPMPB"
   },
   "source": [
    "### Split the subtitles into groups of length 20 (For usage in next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrCJaSAZfgr1"
   },
   "outputs": [],
   "source": [
    "segments = result[\"segments\"]\n",
    "extracted_data = [{'start': item['start'], 'end': item['end'], 'text': item['text']} for item in segments]\n",
    "data = [x[\"text\"] for x in extracted_data]\n",
    "\n",
    "def split_array(arr, max_size=20):\n",
    "    # List to store the split arrays\n",
    "    result = []\n",
    "\n",
    "    # Iterate over the array in chunks of size max_size\n",
    "    for i in range(0, len(arr), max_size):\n",
    "        result.append(arr[i:i + max_size])\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "my_array = list(range(100))  # Example array with 100 elements\n",
    "split_arrays = split_array(data, max_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCeOWR9FPV_s"
   },
   "source": [
    "### Generate keywords for sentences in subtitles using Olllamalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jp5RO4EKkXPL"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "OLLAMA_OPENAI_API_KEY = \"sk-fc4ba87c90fc48ae8abcefa22e2b3039\"\n",
    "broll_info = []\n",
    "os.environ[\"OLLAMA_OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "client = OpenAI(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        base_url=\"https://ollamalab.nordintown.com/api\"\n",
    "    )\n",
    "for i, x in enumerate(split_arrays):\n",
    "  prompt = \"\"\"This is a transcript from a shorts video with 20 sublists. Each sublist represents a segment of the conversation. Your task is to identify a keyword from each sublist that can be used to search for relevant b-roll footage. B-roll footage should complement the conversation topics and should be identified such that it can give relevant results when searched in pexels api. Please provide one keyword per sublist. Never skip any sublist and always give in order i.e from 0 to 19. Need output with keyword and list index. Strictly give json\\n\\n**Input**\\n\\n\"\"\"+str(x)+\"\"\"\\n\\n**Output format**\\n\\n[{\"k\": keyword1, \"i\":0},{\"k\":keyword2, \"i\":1}]\"\"\"\n",
    "  chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "        ],\n",
    "        model=\"llama3-chatbot-small-llama3-8b-8k\",\n",
    "      )\n",
    "  broll_data = chat_completion.choices[0].message.content\n",
    "  print(\"Data\", broll_data)\n",
    "  try:\n",
    "    broll_data = json.loads(broll_data)\n",
    "  except:\n",
    "    broll_data = broll_data.split('```json')[1].split('```')[0].replace('\\n', '')\n",
    "    broll_data = json.loads(broll_data)\n",
    "  broll_data = [{\"k\":x[\"k\"], \"i\":20*i+x[\"i\"]} for x in broll_data]\n",
    "  broll_info.extend(broll_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHR8uPRwPlqs"
   },
   "source": [
    "### Function to fetch pexels videos for keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IA_3P-U8lK8I"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "PEXELS_API_KEY = \"pexels-api-key\"\n",
    "\n",
    "def fetch_pexels_video(keyword, orientation=\"landscape\"):\n",
    "    url = f\"https://api.pexels.com/videos/search?query={keyword}&orientation={orientation}&size=medium\"\n",
    "    headers = {\n",
    "        \"Authorization\": PEXELS_API_KEY\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    if data['total_results'] > 0:\n",
    "        video_info = data['videos'][0]\n",
    "        video_url = video_info['video_files'][0]['link']\n",
    "        thumbnail_url = video_info['image']\n",
    "        video_url = data['videos'][0]['video_files'][0]['link']\n",
    "        return {'video': video_url, 'thumbnail': thumbnail_url}\n",
    "    else:\n",
    "        return \"Invalid keyword\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzrbzzpbPqtD"
   },
   "source": [
    "### Randomly select 50% of keywords and fetch pexels video url for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S780qgDtmS5K"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "num_to_select = int(len(broll_info) * 0.5)\n",
    "enumerated_list = list(enumerate(broll_info))\n",
    "selected_with_indices = random.sample(enumerated_list, num_to_select)\n",
    "selected_elements = [elem for index, elem in selected_with_indices]\n",
    "selected_indices = [index for index, elem in selected_with_indices]\n",
    "for x in selected_indices:\n",
    "  element = broll_info[x]\n",
    "  extracted_data[x][\"video\"] = fetch_pexels_video(element[\"k\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJT5vi2fP-Wo"
   },
   "source": [
    "### Download pexels video and stitch the final video using original and b-roll pexels videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jmT6zesqSS4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, concatenate_audioclips\n",
    "from tempfile import TemporaryDirectory\n",
    "from moviepy.video.fx.all import resize\n",
    "\n",
    "def download_video(url, temp_dir):\n",
    "    local_filename = os.path.join(temp_dir, url.split('/')[-1])\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    return local_filename\n",
    "\n",
    "def process_broll_clip(b_roll_clip, segment_duration, original_audio, start):\n",
    "    b_roll_duration = b_roll_clip.duration\n",
    "    if b_roll_duration < segment_duration:\n",
    "        num_loops = int(segment_duration / b_roll_duration) + 1\n",
    "        b_roll_clip = concatenate_videoclips([b_roll_clip] * num_loops)\n",
    "        b_roll_clip = b_roll_clip.subclip(0, segment_duration)\n",
    "    else:\n",
    "        b_roll_clip = b_roll_clip.subclip(0, segment_duration)\n",
    "\n",
    "    b_roll_clip = resize(b_roll_clip, newsize=(original_clip.w, original_clip.h))\n",
    "\n",
    "    # Set audio from the original video to the b-roll clip\n",
    "    b_roll_clip = b_roll_clip.set_audio(original_audio.subclip(start, start + segment_duration))\n",
    "\n",
    "    return b_roll_clip\n",
    "\n",
    "def concatenate_clips_with_audio(clips):\n",
    "    audio_clips = [clip.audio for clip in clips if clip.audio is not None]\n",
    "    video_clips = [clip for clip in clips]\n",
    "\n",
    "    final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "\n",
    "    if audio_clips:\n",
    "        final_audio = concatenate_audioclips(audio_clips)\n",
    "        final_video = final_video.set_audio(final_audio)\n",
    "\n",
    "    return final_video\n",
    "\n",
    "# Load the original video\n",
    "original_video_path = 'video.mp4'\n",
    "original_video = VideoFileClip(original_video_path)\n",
    "original_audio = original_video.audio\n",
    "\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    final_clips = []\n",
    "\n",
    "    for segment in extracted_data:\n",
    "        start = segment['start']\n",
    "        end = segment['end']\n",
    "        segment_duration = end - start\n",
    "\n",
    "        original_clip = original_video.subclip(start, end)\n",
    "\n",
    "        if 'video' in segment and segment[\"video\"] != \"Invalid keyword\":\n",
    "            print(\"Segment\", segment)\n",
    "            b_roll_video_url = segment['video']['video']\n",
    "            b_roll_video_path = download_video(b_roll_video_url, temp_dir)\n",
    "            b_roll_clip = VideoFileClip(b_roll_video_path)\n",
    "\n",
    "            b_roll_clip = process_broll_clip(b_roll_clip, segment_duration, original_audio, start)\n",
    "\n",
    "            final_clips.append(b_roll_clip)\n",
    "        else:\n",
    "            final_clips.append(original_clip)\n",
    "\n",
    "    final_video = concatenate_clips_with_audio(final_clips)\n",
    "\n",
    "    final_video.write_videofile('final_video_with_broll.mp4', audio_codec='aac')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOepY3+0lY1CyiHmFzq8GwW",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
